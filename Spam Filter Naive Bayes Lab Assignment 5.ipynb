{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baking-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-surgeon",
   "metadata": {},
   "source": [
    "# Generating stop words and stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "taken-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "ps = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-violation",
   "metadata": {},
   "source": [
    "# Reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "static-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(fileName):\n",
    "   \n",
    "    rows  =  []\n",
    "    result = []\n",
    "    \n",
    "    with open(fileName, 'r',encoding=\"utf8\") as csvfile:\n",
    "\n",
    "        # creating a csv reader object\n",
    "        csvreader = csv.reader(csvfile)\n",
    "\n",
    "        # ignoring column heading\n",
    "        next(csvreader)\n",
    "\n",
    "        # extracting each data row one by one\n",
    "        for row in csvreader:\n",
    "            rows.append(row[:2])\n",
    "    return rows\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-advocate",
   "metadata": {},
   "source": [
    "# Cleaning and tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "searching-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAndTokenizeSentence(sentence):\n",
    "        text = []\n",
    "        sentence = sentence.strip().lower().split()\n",
    "        for word in sentence:\n",
    "            text.append(\"\".join(w for w in re.findall(\"([a-z\\-.']+)\", word)))\n",
    "        text = \" \".join(text)\n",
    "        for key, val in dict({'‚Äú': '\"', '‚Äù': '\"', '‚Äô': \"'\", '--': ','}).items():\n",
    "            text = text.replace(key,val)\n",
    "        \n",
    "        cleanWords = []\n",
    "        for word in nltk.tokenize.word_tokenize(text):\n",
    "            word = ps.stem(word)\n",
    "            if word not in stop_words and word != '.' * len(word):\n",
    "                cleanWords.append(word)\n",
    "        return cleanWords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-binding",
   "metadata": {},
   "source": [
    "# Splitting testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changed-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainAndTestData(rows, percent = 0.9,seed = 30):    \n",
    "    random.seed(seed)\n",
    "    rows.sort()\n",
    "    trainSize = int(len(rows) * percent)\n",
    "    random.shuffle(rows)\n",
    "    return rows[:trainSize] , rows[trainSize:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-monte",
   "metadata": {},
   "source": [
    "# NaiveBayes class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amateur-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class naiveBayes:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.trainCount = defaultdict(lambda: defaultdict(int));\n",
    "        self.totalWordsinClass = defaultdict(int);\n",
    "        self.classCount = defaultdict(int)\n",
    "        self.trainOnce = False\n",
    "    \n",
    "    def train(self):\n",
    "        if self.trainOnce == True:\n",
    "            return\n",
    "        self.trainOnce = True \n",
    "        for i in range(len(self.data)):\n",
    "            self.data[i][1] = cleanAndTokenizeSentence(self.data[i][1]) \n",
    "            self.classCount[self.data[i][0]]+=1\n",
    "            for word in self.data[i][1]:\n",
    "                #return self.data[1]\n",
    "                self.trainCount[self.data[i][0]][word]  += 1\n",
    "                self.totalWordsinClass[self.data[i][0]] += 1\n",
    "    \n",
    "    def test(self, sentence, tell_all_word_prob = False):\n",
    "        def myPrint(*args):\n",
    "            if tell_all_word_prob:\n",
    "                print(\" \".join(args))\n",
    "            \n",
    "        all_prob = []\n",
    "        #return sentence\n",
    "        myPrint(f'->Test Sentence is:\\n',sentence,'\\n')\n",
    "        sentence = cleanAndTokenizeSentence(sentence)\n",
    "        myPrint(f'tokens\\n{sentence}')\n",
    "        \n",
    "        #print(sentence)\n",
    "        #return self.classCount\n",
    "        for key in self.classCount:\n",
    "            myPrint(f\"for class {key}\")\n",
    "            #print(\"hi\")\n",
    "            prob = 1.0\n",
    "            for token in sentence:\n",
    "                if token not in self.trainCount[key].keys():\n",
    "                    num = 0\n",
    "                else:\n",
    "                    num = self.trainCount[key][token];\n",
    "                denum = self.totalWordsinClass[key]\n",
    "                num += 1                              # add one smooting\n",
    "                denum += len(self.trainCount[key])    #add one smooting\n",
    "                prob *= num / denum\n",
    "                myPrint(\"\\t\",f\"the probability of word ({token}) is {num / denum}\")\n",
    "            prob *= self.classCount[key] / len(self.data)\n",
    "            #print(prob)\n",
    "            \n",
    "            all_prob.append((prob, key))\n",
    "        all_prob.sort(reverse=True)\n",
    "        total = 0\n",
    "        for x in all_prob:\n",
    "            total += x[0];\n",
    "        #print(total)    \n",
    "        return (round(all_prob[0][0]/total*100,2),all_prob[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-british",
   "metadata": {},
   "source": [
    "# starting function execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pressing-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = readCSV(r\"./Dataset Message Spam - NLP Lab sample.csv - Dataset Message Spam - NLP Lab sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "popular-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = splitTrainAndTestData(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-throw",
   "metadata": {},
   "source": [
    "# Creating and Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indirect-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = naiveBayes(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "general-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-preservation",
   "metadata": {},
   "source": [
    "# Class Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "meaning-shape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the probability of class (ham) is 48.89\n",
      "the probability of class (spam) is 51.11\n"
     ]
    }
   ],
   "source": [
    "for key in model.classCount:\n",
    "    print(f\"the probability of class ({key}) is {round(model.classCount[key]/len(model.data)*100,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-suggestion",
   "metadata": {},
   "source": [
    "# Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "developmental-complexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->Test Sentence is:\n",
      " Ffffffffff. Alright no way I can meet up with you sooner? \n",
      "\n",
      "tokens\n",
      "['ffffffffff', 'alright', 'way', 'meet', 'sooner']\n",
      "for class ham\n",
      "\t the probability of word (ffffffffff) is 0.0007598784194528875\n",
      "\t the probability of word (alright) is 0.0007598784194528875\n",
      "\t the probability of word (way) is 0.003799392097264438\n",
      "\t the probability of word (meet) is 0.0022796352583586625\n",
      "\t the probability of word (sooner) is 0.0007598784194528875\n",
      "for class spam\n",
      "\t the probability of word (ffffffffff) is 0.0005125576627370579\n",
      "\t the probability of word (alright) is 0.0005125576627370579\n",
      "\t the probability of word (way) is 0.0010251153254741158\n",
      "\t the probability of word (meet) is 0.0015376729882111738\n",
      "\t the probability of word (sooner) is 0.0005125576627370579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94.48, 'ham')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]\n",
    "model.test(test[0][1],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "neural-postcard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Ffffffffff. Alright no way I can meet up with you sooner? ********** \n",
      "\n",
      "it's a HAM with 94.48% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune ********** \n",
      "\n",
      "it's a HAM with 98.63% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Ok lar... Joking wif u oni... ********** \n",
      "\n",
      "it's a HAM with 99.94% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** GENT! We are trying to contact you. Last weekends draw shows that you won a Êæπ1000 prize GUARANTEED. Call 09064012160. Claim Code K52. Valid 12hrs only. 150ppm ********** \n",
      "\n",
      "it's a SPAM with 100.0% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already? ********** \n",
      "\n",
      "it's a HAM with 100.0% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Congratulations ur awarded 500 of CD vouchers or 125gift guaranteed & Free entry 2 100 wkly draw txt MUSIC to 87066 TnCs www.Ldew.com1win150ppmx3age16 ********** \n",
      "\n",
      "it's a SPAM with 100.0% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Finished class where are you. ********** \n",
      "\n",
      "it's a HAM with 92.65% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** I HAVE A DATE ON SUNDAY WITH WILL!! ********** \n",
      "\n",
      "my code says it is SPAM with 76.9% surety but it is not üò®\n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Todays Voda numbers ending 7548 are selected to receive a $350 award. If you have a match please call 08712300220 quoting claim code 4041 standard rates app ********** \n",
      "\n",
      "it's a SPAM with 100.0% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Yup next stop. ********** \n",
      "\n",
      "my code says it is SPAM with 86.22% surety but it is not üò®\n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** -PLS STOP bootydelious (32/F) is inviting you to be her friend. Reply YES-434 or NO-434 See her: www.SMS.ac/u/bootydelious STOP? Send STOP FRND to 62468 ********** \n",
      "\n",
      "it's a SPAM with 96.72% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Does not operate after  &lt;#&gt;  or what ********** \n",
      "\n",
      "it's a HAM with 94.33% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Please don't text me anymore. I have nothing else to say. ********** \n",
      "\n",
      "it's a HAM with 83.6% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** K tell me anything about you. ********** \n",
      "\n",
      "it's a HAM with 99.68% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** URGENT! We are trying to contact you. Last weekends draw shows that you have won a Êæπ900 prize GUARANTEED. Call 09061701939. Claim code S89. Valid 12hrs only ********** \n",
      "\n",
      "it's a SPAM with 100.0% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Thanks for your Ringtone Order, Reference T91. You will be charged GBP 4 per week. You can unsubscribe at anytime by calling customer services on 09057039994 ********** \n",
      "\n",
      "it's a SPAM with 100.0% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune ********** \n",
      "\n",
      "it's a HAM with 98.63% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Sunshine Quiz Wkly Q! Win a top Sony DVD player if u know which country the Algarve is in? Txt ansr to 82277. Êæπ1.50 SP:Tyrone ********** \n",
      "\n",
      "it's a SPAM with 89.12% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Thanks a lot for your wishes on my birthday. Thanks you for making my birthday truly memorable. ********** \n",
      "\n",
      "it's a HAM with 99.25% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "********** Here is your discount code RP176781. To stop further messages reply stop. www.regalportfolio.co.uk. Customer Services 08717205546 ********** \n",
      "\n",
      "it's a SPAM with 100.0% surety üòÅ \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "countCorrect = 0\n",
    "for t in test:\n",
    "    to_string = t[1]\n",
    "    print('*'*10,to_string,'*'*10,'\\n')\n",
    "    x = model.test(to_string)\n",
    "    if t[0] == x[1]:\n",
    "        countCorrect += 1\n",
    "        print(f\"it's a {x[1].upper()} with {x[0]}% surety üòÅ \")\n",
    "    else:\n",
    "        print(f\"my code says it is {x[1].upper()} with {x[0]}% surety but it is not üò®\")\n",
    "    print('-' * 100)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-holiday",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conceptual-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count is 20 and correct count is 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"total count is {len(test)} and correct count is {countCorrect}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dedicated-tamil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 90.0 % \n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the model is {countCorrect/len(test) * 100} % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-inspiration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-netherlands",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
